{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c53ce78-83f6-4074-8fdf-2ca74ca98888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cad60f99-242d-405e-835e-db48b97f2cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(os.pardir, '175Project')\n",
    "\n",
    "COL_NAMES = ['character', 'browsing_page_url', 'word_url', 'word', 'definition', 'sentence']\n",
    "\n",
    "def load_urban_dataset():\n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(os.path.join(DATA_DIR, 'Urban')):\n",
    "        for f in files:\n",
    "            if f.endswith('.csv') and f.startswith('urban_data'):\n",
    "                file_paths.append(os.path.join(root, f))\n",
    "    df_urban = pd.concat([pd.read_csv(f, names=COL_NAMES) for f in file_paths])\n",
    "\n",
    "    df_nulls = df_urban[(df_urban.isnull().any(axis=1)) | (df_urban.isna().any(axis=1))]\n",
    "    df_urban = df_urban.drop(df_nulls.index)\n",
    "\n",
    "    return df_urban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2293662-143e-41a8-87a9-d34717dff462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of urban dictionary dataset: (2175494, 6)\n",
      "Word:  Blow glass\n",
      "Meaning:  Yacht  exscursion in the a.m watching/ snapping the water spray out the back of the  yacht  as you leave the  harbor .\n",
      "Sentence:  Snapchat a  clip  of the moment with a  caption . “Do you  blow glass ?”\n"
     ]
    }
   ],
   "source": [
    "urban_dictionary = load_urban_dataset()\n",
    "print(f\"Shape of urban dictionary dataset: {urban_dictionary.shape}\")\n",
    "ud_sample = urban_dictionary[['word', 'definition', 'sentence']].sample(1)\n",
    "for i in ud_sample.values:\n",
    "    print(\"Word: \", i[0])\n",
    "    print(\"Meaning: \", i[1])\n",
    "    print(\"Sentence: \", i[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8d4c9ee-1492-4b97-a44a-ce6d5ec7321b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word                                                     Adeogo\n",
      "definition    A beautiful tall black girl who's future job i...\n",
      "sentence      Adeogo has been  playing the violin   for 7   ...\n",
      "Name: 17480, dtype: object\n",
      "\n",
      "The full item\n",
      "\n",
      "['Adeogo'\n",
      " \"A beautiful tall black girl who's future job is a fashion model for high and popular brands, like Gucci, Dior,  MCM , Louis Vuitton,  Balenciaga  and more. Her horoscope sign is cancer. She could  play the violin  really well. She could also be annoying sometimes, but she's smart and always loves to watch movies and is always kind and loves to spend time with family and friends.\"\n",
      " 'Adeogo has been  playing the violin   for 7   years  since she was 6.']\n"
     ]
    }
   ],
   "source": [
    "urban_data = urban_dictionary[['word', 'definition', 'sentence']]\n",
    "train_u, test_u = train_test_split(urban_data, test_size=0.2, random_state=42, shuffle=True)\n",
    "#example of what the data looks like\n",
    "row = train_u.iloc[0]\n",
    "print(row)\n",
    "print()\n",
    "print(\"The full item\")\n",
    "print()\n",
    "print(row.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55d0cde9-3b88-454e-af6d-4c5940029a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configuration file found at C:\\Users\\brock/.convokit/config.yml; writing with contents: \n",
      "# Default Backend Parameters\n",
      "db_host: localhost:27017\n",
      "data_directory: ~/.convokit/saved-corpora\n",
      "model_directory: ~/.convokit/saved-models\n",
      "default_backend: mem\n",
      "Downloading movie-corpus to C:\\Users\\brock\\.convokit\\saved-corpora\\movie-corpus\n",
      "Downloading movie-corpus from http://zissou.infosci.cornell.edu/convokit/datasets/movie-corpus/movie-corpus.zip (40.9MB)... Done\n"
     ]
    }
   ],
   "source": [
    "from convokit import Corpus, download\n",
    "corpus = Corpus(filename=download(\"movie-corpus\"))\n",
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b06e530b-22e0-4c4b-ace8-8f173746e694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 9035\n",
      "Number of Utterances: 304713\n",
      "Number of Conversations: 83097\n"
     ]
    }
   ],
   "source": [
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "112afb88-b3f2-4e14-8953-a094fcb033d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total conversations: 83097\n",
      "Example conversation: ['They do not!', 'They do to!']\n"
     ]
    }
   ],
   "source": [
    "conversations_raw = []\n",
    "\n",
    "# Iterate over all conversation IDs\n",
    "for convo_id in corpus.get_conversation_ids():\n",
    "    convo = corpus.get_conversation(convo_id)\n",
    "    # Extract the textual content of each utterance in the conversation\n",
    "    convo_text = [utt.text for utt in convo.iter_utterances()]\n",
    "    conversations_raw.append(convo_text)\n",
    "\n",
    "print(f\"Total conversations: {len(conversations_raw)}\")\n",
    "print(\"Example conversation:\", conversations_raw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b4cdb9d-5106-48b4-8c7b-b72d3790fd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs: 221616\n",
      "Sample pair: ('They do not!', 'They do to!')\n"
     ]
    }
   ],
   "source": [
    "pairs = []\n",
    "for convo in conversations_raw:\n",
    "    for i in range(len(convo)-1):\n",
    "        pairs.append((convo[i], convo[i+1]))\n",
    "\n",
    "print(f\"Total pairs: {len(pairs)}\")\n",
    "print(\"Sample pair:\", pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03a0bfad-1b14-421f-a80a-802827967482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train conversations: 66477, Test conversations: 16620\n"
     ]
    }
   ],
   "source": [
    "train_convos, test_convos = train_test_split(conversations_raw, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a2cc4bf-ce56-49bb-88bb-3a1c73b5c5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total utterances: 304713\n",
      "Example utterances: ['They do not!', 'They do to!', 'I hope so.', 'She okay?', \"Let's go.\"]\n"
     ]
    }
   ],
   "source": [
    "all_texts = [utt.text for utt in corpus.iter_utterances()]\n",
    "\n",
    "print(f\"Total utterances: {len(all_texts)}\")\n",
    "print(\"Example utterances:\", all_texts[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e540d87-0eed-46a7-a10f-ec9c4bd826ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts = train_test_split(all_texts, test_size=0.2, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
